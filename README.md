# Models and Papers Exploration
The goal of this repository is to explore and implement cutting-edge models and papers from scratch. This allows me to understand the nuances of each model, while also giving others an opportunity to follow along and learn. Each implementation includes detailed comments, explanations, and test scripts to demonstrate the models' performance.

## Implemented Models
Hereâ€™s a list of the models and papers implemented so far:

1. **Vision Transformer (ViT)**
   - Paper: ["An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"](https://arxiv.org/abs/2010.11929)
   - Implementation: [Link to ViT Implementation](./VIT_from_scratch)

## Used Setup
For all of these experiments I have trained / tested the models using Nvidia RTX 4090 GPU. The logs of the training and/or testing are omitted from this repository.
## How to Use
To run any of the implemented models, follow the instructions in each model's respective folder. Here's a basic workflow:

1. **Clone the repository:**
   ```bash
   git clone https://github.com/your-username/your-repo-name.git
   cd your-repo-name

2. **we will find the main.py which you can run directly after seting up your conda/venv environment
